{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tutoriel 4 - transfert d'apprentissage (Transfer learning)\n",
    "---\n",
    "\n",
    "<center><img src=\"./img/mlprocess_3.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n",
    "\n",
    "Dans ce tutoriel, nous allons effectuer ce qu'on appelle le transfert d'apprentissage. Pour ce faire, nous allons utiliser un réseau de neurones à convolution de type [ResNet](https://en.wikipedia.org/wiki/Residual_neural_network) qui a été préentraîné avec le jeu de données [ImageNet](https://fr.wikipedia.org/wiki/ImageNet). Étant donné que les données d’ImageNet sont assez semblables à ceux de CIFAR10, le réseau ResNet préentraîné est capable d'extraire des features (attributs) utiles à la détection d'objet. On peut donc s'attendre à de meilleures performances sur CIFAR10. \n",
    "\n",
    "Pour effectuer le transfert, la mécanique est la suivante. Les poids préentraînés du ResNet sont chargés dans notre modèle PyTorch. Étant donné qu’ImageNet a 1000 classes et que CIFAR10 en a seulement 10, la couche du ResNet qui fait la classification (aussi nommée tête du réseau) est changée afin d'avoir seulement 10 sorties au lieu de 1000. Une fois cela fait, nous pouvons entraîner le réseau avec CIFAR10. \n",
    "\n",
    "Il est possible de n'entraîner que la tête du réseau ou seulement quelques couches. Le choix du nombre de couches à entraîner va influer sur la performance du modèle ainsi que le temps d'entraînement. N'entraîner que la tête permet d'extraire des représentations utiles des exemples et peu permettre un entraînement très rapide. Toutefois, entraîner toutes les couches du réseau permet d'extraire des représentations mieux adaptées aux exemples, au prix d'un entraînement plus long. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim, nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.init import kaiming_normal_, constant_\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from poutyne.framework import Model, ModelCheckpoint, Callback, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from poutyne import torch_to_numpy\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres d'entraînement\n",
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "n_epoch = 5\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(download=False, path='./', transform=None):\n",
    "    \"\"\"Loads the cifar10 dataset.\n",
    "\n",
    "    :param download: Download the dataset\n",
    "    :param path: Folder to put the dataset\n",
    "    :return: The train and test dataset\n",
    "    \"\"\"\n",
    "    train_dataset = CIFAR10(path, train=True, download=download, transform=transform)\n",
    "    test_dataset = CIFAR10(path, train=False, download=download, transform=transform)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def load_cifar10_with_validation_set(download=False, path='./', train_split=0.8):\n",
    "    \"\"\"Loads the CIFAR10 dataset.\n",
    "\n",
    "    :param download: Download the dataset\n",
    "    :param path: Folder to put the dataset\n",
    "    :return: The train, valid and test dataset ready to be ingest in a neural network\n",
    "    \"\"\"\n",
    "    train, test = load_cifar10(download, path)\n",
    "    lengths = [round(train_split*len(train)), round((1.0-train_split)*len(train))]\n",
    "    train, valid = random_split(train, lengths)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de pipelines de transformation et d'augmentation d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_coefs = {}\n",
    "norm_coefs['imagenet'] = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "\n",
    "# Pipeline de prétraitement d'images.\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*norm_coefs['imagenet'])\n",
    "])\n",
    "\n",
    "# Pipeline de prétraitement et d'augmentation d'images.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*norm_coefs['imagenet'])\n",
    "])\n",
    "\n",
    "# Chargement des images et séparation en 3 ensembles d'entraînement, de validation et de test.\n",
    "train, valid, test = load_cifar10_with_validation_set(download=True)\n",
    "\n",
    "# Assignation des pipelines aux ensembles correspondants. N.B. L'augmentation d'images n'est appliquée \n",
    "# qu'à l'ensemble d'entraînement.\n",
    "train.dataset.transform = train_transforms\n",
    "valid.dataset.transform = test_transforms\n",
    "test.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres d'images dans les ensembles d'entraînement, de validation et de test.\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des chargeurs de données (`dataloaders`) qui vont nous fournir `batch_size` images à la fois, c'est-à-dire des lots (`batchs`) de taille `batch_size`. Nous avons 3  chargeurs de données pour les 3 ensembles utilisés: entraînement, validation et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name, network, params=None):\n",
    "    if not params:\n",
    "        params = network.parameters()\n",
    "    \n",
    "    optimizer = optim.SGD(params, lr=learning_rate, momentum=0.9)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(patience=5, verbose=True)\n",
    "    callbacks = [early_stopping, lr_scheduler]\n",
    "\n",
    "    # Objet Model de Poutyne\n",
    "    model = Model(network, optimizer, loss_function, batch_metrics=['accuracy'])\n",
    "\n",
    "    # Envoi du modèle sur GPUs si disponibles\n",
    "    model.to(device)\n",
    "\n",
    "    # Lancement de l'entraînement\n",
    "    model.fit_generator(train_loader, valid_loader, epochs=n_epoch, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous allons entraîner seulement la dernière couche pour classifier 10 classes.\n",
    "\n",
    "Nous devons modifier la dernière couche du réseau ResNet-34 (préentraîné sur imageNet) pour avoir le bon nombre de classes en sortie.  En effet, le jeu de données que nous utilisons, CIFAR10, ne contient que 10 classes au lieu des 1000 d'ImageNet. Ces 1000 classes nous sont inutiles; on doit s'en débarrasser afin de se concentrer sur les 10 de CIFAR10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chargement du réseau ResNet de 34 couches avec ses poids préentraînés sur ImageNet\n",
    "net = models.resnet34(pretrained=True)\n",
    "\n",
    "# Remplacement de la couche de classification\n",
    "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entraîner seulement la dernière couche, en PyTorch, nous pouvons n'envoyer que les paramètres de cette couche à l'optimiseur. Les autres paramètres resteront inchangés.\n",
    "\n",
    "Nous en profitons pour bien initialiser les nouveaux paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_for_last_layer_only(net):\n",
    "    # Filter params\n",
    "    classification_layer_params = [(n, p) for n, p in net.named_parameters() if 'fc' in n]\n",
    "    \n",
    "    # Initialize those\n",
    "    for n, p in classification_layer_params:\n",
    "        if 'weight' in n:\n",
    "            kaiming_normal_(p)\n",
    "        if 'bias' in n:\n",
    "            constant_(p, 0)\n",
    "    \n",
    "    # Return the list of different params/learning rates\n",
    "    classification_layer_params = [p for _, p in classification_layer_params]\n",
    "    return [\n",
    "        {'params': classification_layer_params, 'lr': 1e-2, 'momentum':0.9},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_lr_for_last_layer_only(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train('deep_net', net, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ici nous allons entraîner la dernière couche et peaufiner l'ensemble du réseau.\n",
    "\n",
    "Même principe qu'à l'étape précédente, mais nous allons spécifier, cette fois-ci, différents taux d'apprentissage à travers le réseau. Ainsi, les couches préentraînées auront un taux d'apprentissage plus petit et la nouvelle couche de classification aura un taux standard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_for_last_layer_and_fine_tune_conv(net):\n",
    "    # Filter params\n",
    "    classification_layer_params = [(n, p) for n, p in net.named_parameters() if 'fc' in n]\n",
    "    convolutional_layer_params = [p for n, p in net.named_parameters() if 'fc' not in n]\n",
    "    \n",
    "    # Initialize those\n",
    "    for n, p in classification_layer_params:\n",
    "        if 'weight' in n:\n",
    "            kaiming_normal_(p)\n",
    "        if 'bias' in n:\n",
    "            constant_(p, 0)\n",
    "    \n",
    "    # Return the list of different params/learning rates\n",
    "    classification_layer_params = [p for _, p in classification_layer_params]\n",
    "    return [\n",
    "        {'params': classification_layer_params, 'lr': 1e-2, 'momentum':0.9},\n",
    "        {'params': convolutional_layer_params, 'lr': 1e-4, 'momentum':0.9},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet34(pretrained=True)\n",
    "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "params = get_lr_for_last_layer_and_fine_tune_conv(net)\n",
    "model = train('deep_net', net, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous pouvons aussi effectuer un apprentissage complet du réseau et voir si les résultats s'améliorent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet34(pretrained=True)\n",
    "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "model = train('deep_net', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4oZQu24WPIv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tutoriel 1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
