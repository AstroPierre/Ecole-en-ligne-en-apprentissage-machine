{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U6gtvbQZJYFc"
   },
   "source": [
    "___\n",
    "\n",
    "# 0 - Préambule\n",
    "\n",
    "Ce module (facultatif, mais intéressant, sinon on ne l'aurait pas mis) vous présente les différents liens dans le processus de formation. Aucune théorie ne vous sera donnée sur le module 0 ci-dessous, car c'est très *pratico-pratique*, c.-à-d. très dépendant des données et des problèmes rencontrés dans les données. \n",
    "\n",
    "Un projet d'apprentissage automatique peut généralement se formuler de la manière suivante : \n",
    "\n",
    "<center><img src=\"./img/mlprocess_0.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n",
    "\n",
    "Où les blocs représentent :\n",
    "\n",
    "1. Collecte et évaluation de la qualité des données.\n",
    "2. Nettoyage et préparation des données.\n",
    "3. Création des modèles.\n",
    "4. Évaluation et sélection des modèles.\n",
    "5. Mise en production et maintenance.\n",
    "\n",
    "La formation couvre une certaine partie de ces blocs, nommément les blocs 3 et 4, qui consistent dans la modélisation et l'évaluation de solutions adaptées aux données en vue d'en faire une preuve de concept. Cependant, dans ce _notebook_, nous allons couvrir rapidement le bloc 1, *la collecte* et le bloc 2, *la préparation*, car vous aurez avec certitude à faire face à ce genre de problèmes dans votre future vie d'analyste de données.\n",
    "\n",
    "Il existe d'ailleurs une maxime à ce sujet : \n",
    "\n",
    "## \"Data-scientists only work on Friday\"\n",
    "\n",
    "La métaphore explique que 80% du temps (si ce n'est plus) consiste en analyse, nettoyage, préparation et visualisation des données en vue d'en appréhender la nature et les tendances qui s'en dégagent. Les outils ci-après vont vous aider à faire ceci.\n",
    "\n",
    "\n",
    "# 0.1 *Notebooks*\n",
    "\n",
    "Ceci est un *jupyter notebook*. Si vous n'en avez jamais utilisé auparavant, visitez la [page de l'université de Paris VII](https://python.sdv.univ-paris-diderot.fr/18_jupyter/). Si vous aimez les raccourcis clavier, [la page suivante devrait vous aider](https://www.edureka.co/blog/wp-content/uploads/2018/10/Jupyter_Notebook_CheatSheet_Edureka.pdf).\n",
    "\n",
    "Cependant, étant donné que certaines fonctionnalités ont été désactivées pour mieux intégrer les notebooks sur cette plateforme d'apprentissage, il se peut que vous ne puissiez pas tous les utiliser.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4S_ulIGUJYFc"
   },
   "source": [
    "# Pré-préparation : Collecte et évaluation de la qualité des données\n",
    "---\n",
    "\n",
    "<center><img src=\"./img/mlprocess_1.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n",
    "\n",
    "## Collecte et colligation : Que regarder ?\n",
    "### VALIDITÉ\n",
    "- Existe-t-il une relation directe entre l'activité et ce qui est mesuré?\n",
    "- Les données sont-elles désagrégées de manière appropriée?\n",
    "- Les personnes qui collectent les données sont-elles qualifiées et bien supervisées?\n",
    "- Des mesures sont-elles prises pour corriger les données erronées?\n",
    "- Les problèmes de collecte de données connus ont-ils été correctement évalués?\n",
    "- Des mesures sont-elles prises pour limiter les erreurs de transcription?\n",
    "- Les problèmes de qualité des données sont-ils clairement décrits dans les rapports finaux?\n",
    "\n",
    "### FIABILITÉ\n",
    "- Un processus cohérent de collecte de données est-il utilisé d'année en année, d'une source à l'autre?\n",
    "- Existe-t-il des procédures permettant un examen périodique de la collecte, la maintenance et le suivi des données, ainsi que leur documentation par écrit?\n",
    "\n",
    "### TEMPORALITÉ\n",
    "- Un calendrier de collecte de données régularisé est-il en place pour répondre aux besoins de gestion du programme?\n",
    "- Les données sont-elles correctement stockées et facilement disponibles?\n",
    "\n",
    "### PRÉCISION\n",
    "- Existe-t-il une méthode pour détecter les données en double?\n",
    "- Existe-t-il une méthode pour détecter les données manquantes?\n",
    "\n",
    "### INTÉGRITÉ\n",
    "- Des mesures de protection appropriées sont-elles en place afin d'empêcher les modifications non autorisées de données?\n",
    "- Un examen indépendant des résultats rapportés est-il nécessaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uW0toEHZJYFc"
   },
   "source": [
    "## Ce que vous cherchez a-t-il un sens?\n",
    "\n",
    "Regardez les données. S'il s'agit d'un jeu de données volumineux, examinez les 20 premières lignes, les 20 dernières lignes et un échantillon aléatoire de 20 lignes. Vous trouverez ci-dessous des questions que vous devriez vous poser.\n",
    "\n",
    "### L'organisation des données a-t-elle un sens? Les données correspondent-elles à l'étiquette de la colonne?\n",
    "Y a-t-il des noms dans les colonnes de noms, des adresses dans les colonnes d'adresses, des numéros de téléphone dans la colonne de numéros de téléphone? Y a-t-il des données différentes dans les colonnes?\n",
    "\n",
    "### Les données de chaque colonne respectent-elles les règles appropriées à son champ?\n",
    "Les caractères d'un nom sont-ils uniquement alphabétiques (Brendan) ou contiennent-ils des chiffres (B4rendan)?\n",
    "La partie numérique d'un numéro de téléphone est-elle de 10 chiffres (5558675309) ou non (675309)?\n",
    "\n",
    "### Calculer des statistiques récapitulatives pour les données numériques. Ont-elles un sens?\n",
    "Si vous traitez avec des données de temps écoulé, la valeur minimale est-elle négative (- 10 secondes)?\n",
    "Si vous traitez avec des données de salaire annuel pour les travailleurs en col bleu, la valeur maximale est-elle quelque chose de bizarre (1 000 000 $)?\n",
    "\n",
    "### Combien de valeurs sont nulles?\n",
    "Le nombre de NULL est-il acceptable? Existe-t-il un modèle indiquant où il y a des valeurs nulles?\n",
    "\n",
    "### Y a-t-il des doublons et sont-ils acceptables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM5YrDaNJYFd"
   },
   "source": [
    "## Les erreurs communes à éviter\n",
    "\n",
    "**1. Préparer les données pour l'analyse sans objectif clair.**\n",
    "L'accès à toutes les données du monde est essentiellement inutile sans but précis. Certes, il peut être intéressant de consulter des tas de données volumineuses, mais pour des raisons de croissance et d’innovation, des objectifs clairement définis aideront à rationaliser l’analyse. Nous vous recommandons de convenir par écrit de ces objectifs pour vous assurer, ainsi que votre équipe, de rester sur la bonne voie lors de la préparation de vos données pour analyse. \n",
    "\n",
    "**2. Déprioriser la visualisation des données.**\n",
    "Lors de la préparation des données pour l’analyse, il est extrêmement facile de se perdre dans les chiffres sans penser à la présentation finale ni même à la révision de l’analyse des données. La visualisation des données est importante, car c’est ainsi que vous, votre équipe et les autres explorez et interprétez les données. \n",
    "\n",
    "**3. Ignorer les problèmes hors du champ des données.**\n",
    "N'oubliez pas que, dans le monde des données, d'autres mesures allant bien au-delà des chiffres et des performances numériques peuvent parfois être prises en compte. Il peut y avoir des problèmes éthiques, culturels ou philosophiques en jeu qui peuvent prévaloir sur l'analyse de données pure. Soyez sensible à ces points de douleur potentiels pour mieux comprendre comment ils peuvent influer sur vos résultats finaux.\n",
    "\n",
    "**4. Entrer les mauvaises données.**\n",
    "Il est même possible que vous commettiez une erreur lors de la saisie des données de base. La saisie ou la fusion d'informations dans la mauvaise ligne, ou colonne, ou l'ajoût d'un zéro accidentel à la fin d'un nombre sont toutes des erreurs humaines incroyablement courantes lors de la préparation des données pour l'analyse.\n",
    "Lorsqu'il s'agit d'analyser des données, tout processus minimisant le risque d'erreur humaine est extrêmement positif. Testez une procédure sur un sous-ensemble des données et automatisez-la.\n",
    "\n",
    "**5. Analyser une population (trop) petite.**\n",
    "Bien qu’il n’existe bien entendu rien de mal à élaborer des analyses pour une petite population, il est important de savoir que les données risquent de ne pas fournir autant d’informations utiles que si votre population était plus nombreuse. Les populations plus petites tendent à produire plus de personnes aberrantes sans suffisamment de corrélations pour discerner ce qui se passe réellement. \n",
    "\n",
    "**6. Normes de nommage incohérentes ou confuses.**\n",
    "Dès le départ, l'organisation et la cohérence sont essentielles lors de la préparation des données pour l'analyse. Si vos conventions de dénomination sont légèrement différentes, vos données sont potentiellement très problématiques. Assurez-vous de mettre en place, dès le début, une convention de noms de variables simplifiée et partagée par tous. Utilisez des termes clairs et qui auront du sens pour ceux avec qui vous envisagez de partager votre analyse. \n",
    "\n",
    "**7. Attention à la duplication!**\n",
    "Cela peut sembler une évidence, mais la duplication est une erreur plutôt commune lors de la préparation des données pour l'analyse. Dupliquer même une infime entrée faussera vos données de manière imprécise, entraînant des prévisions corrompues ou une prise de décision médiocre.\n",
    "\n",
    "**8. Analyse des données altérées.**\n",
    "Vous avez besoin de données propres. Le nettoyage des données peut prendre du temps. Nous avons déjà discuté de la nécessité d'éviter les données en double, mais nous suggérons également d'éliminer les données aberrantes, les données incorrectes, les données manquantes ou les données dépourvues de logique.\n",
    "\n",
    "**9. Influx de données hétéroclites.**\n",
    "Si vous travaillez avec un ensemble de données volumineux, des informations vous parviendront probablement de différentes sources. Assurez-vous que votre pipeline de préparation extrait des données de sources appropriées et que ces données sont compatibles avec lui. \n",
    "\n",
    "**10. Utilisation de données obsolètes.**\n",
    "L’utilisation de données obsolètes peut se produire en cas de problème d’intégration ou de saisie de votre source de données (voir le numéro 9). Portez une attention particulière aux délais si vous êtes chargé d’examiner des données en temps réel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
