{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Évaluation des modèles de classification : Exemple (un peu) plus réaliste\n",
    "---\n",
    "\n",
    "<center><img src=\"./img/mlprocess_4.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n",
    "\n",
    "Dans cette séquence, nous allons repartir d'un ensemble de données beaucoup plus complexe à base d'images de chiffres manuscrits dont le but est d'identifier le chiffre écrit. C'est un problème multiclasse (10 chiffres de 0 à 9) et entraîner un modèle en se basant sur les différentes métriques vues auparavant ne sera pas aussi simple. \n",
    "\n",
    "Cet ensemble de données servira également pour la transition vers l'apprentissage profond.\n",
    "\n",
    "Importons d'abord les librairies nécessaires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, validation_curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_curve, classification_report, fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et définissons l'ensemble de données, téléchargeons-le et chargeons-le en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', \n",
    "                'class 4', 'class 5', 'class 6', 'class 7', 'class 8', 'class 9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(src, cimg):\n",
    "    with gzip.open(src) as gz:\n",
    "        n = struct.unpack('I', gz.read(4))\n",
    "        # Read magic number.\n",
    "        if n[0] != 0x3080000:\n",
    "            raise Exception('Invalid file: unexpected magic number.')\n",
    "        # Read number of entries.\n",
    "        n = struct.unpack('>I', gz.read(4))[0]\n",
    "        if n != cimg:\n",
    "            raise Exception('Invalid file: expected {0} entries.'.format(cimg))\n",
    "        crow = struct.unpack('>I', gz.read(4))[0]\n",
    "        ccol = struct.unpack('>I', gz.read(4))[0]\n",
    "        if crow != 28 or ccol != 28:\n",
    "            raise Exception('Invalid file: expected 28 rows/cols per image.')\n",
    "        # Read data.\n",
    "        res = np.frombuffer(gz.read(cimg * crow * ccol), dtype = np.uint8)\n",
    "    return res.reshape((cimg, crow * ccol))\n",
    "\n",
    "def loadLabels(src, cimg):\n",
    "    with gzip.open(src) as gz:\n",
    "        n = struct.unpack('I', gz.read(4))\n",
    "        # Read magic number.\n",
    "        if n[0] != 0x1080000:\n",
    "            raise Exception('Invalid file: unexpected magic number.')\n",
    "        # Read number of entries.\n",
    "        n = struct.unpack('>I', gz.read(4))\n",
    "        if n[0] != cimg:\n",
    "            raise Exception('Invalid file: expected {0} rows.'.format(cimg))\n",
    "        # Read labels.\n",
    "        res = np.frombuffer(gz.read(cimg), dtype = np.uint8)\n",
    "    return res.reshape((cimg, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\./MNIST/raw/train-images-idx3-ubyte.gzkh05ulhb.tmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-40a2523b62dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#!rm './MNIST/raw/train-images-idx3-ubyte.gz' './MNIST/raw/train-labels-idx1-ubyte.gz' './raw/MNIST/t10k-images-idx3-ubyte.gz' './MNIST/raw/t10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/train-images-idx3-ubyte.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./MNIST/raw/train-images-idx3-ubyte.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mwget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/train-labels-idx1-ubyte.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./MNIST/raw/train-labels-idx1-ubyte.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mwget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/t10k-images-idx3-ubyte.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./MNIST/raw/t10k-images-idx3-ubyte.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wget.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(url, out, bar)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[1;31m# get filename for temp file in current directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmpfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".tmp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmpfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\tempfile.py\u001b[0m in \u001b[0;36mmkstemp\u001b[1;34m(suffix, prefix, dir, text)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bin_openflags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_mkstemp_inner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\tempfile.py\u001b[0m in \u001b[0;36m_mkstemp_inner\u001b[1;34m(dir, pre, suf, flags, output_type)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0o600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mcontinue\u001b[0m    \u001b[1;31m# try again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\./MNIST/raw/train-images-idx3-ubyte.gzkh05ulhb.tmp'"
     ]
    }
   ],
   "source": [
    "import wget \n",
    "\n",
    "!rm './MNIST/raw/train-images-idx3-ubyte.gz' './MNIST/raw/train-labels-idx1-ubyte.gz' './raw/MNIST/t10k-images-idx3-ubyte.gz' './MNIST/raw/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "wget.download('https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/train-images-idx3-ubyte.gz', './MNIST/raw/train-images-idx3-ubyte.gz')\n",
    "wget.download('https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/train-labels-idx1-ubyte.gz', './MNIST/raw/train-labels-idx1-ubyte.gz')\n",
    "wget.download('https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/t10k-images-idx3-ubyte.gz', './MNIST/raw/t10k-images-idx3-ubyte.gz')\n",
    "wget.download('https://github.com/iid-ulaval/EEAA-datasets/raw/master/MNIST/t10k-labels-idx1-ubyte.gz', './MNIST/raw/t10k-labels-idx1-ubyte.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loadData('./MNIST/raw/train-images-idx3-ubyte.gz', 60000)\n",
    "y_train = loadLabels('./MNIST/raw/train-labels-idx1-ubyte.gz', 60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez regarder quelques exemples de données avec le code ci-dessous : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_i = 5050\n",
    "plt.imshow(X_train[example_i,:].reshape(28,28), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Découpage des données de validation\n",
    "\n",
    "Vous devez définir ici le découpage training/validation afin de pouvoir sélectionner votre modèle. Ne touchez pas au test avant la fin de l'exercice ;-) \n",
    "\n",
    "Vu qu'on est en multiclasse, n'oubliez pas d'utiliser la stratification de votre ensemble de données pour garantir que toutes les classes sont bien représentées dans l'ensemble de validation (pour cela utilisez le paramètre `stratify` de [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) en lui passant les étiquettes `y`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbe d'apprentissage\n",
    "\n",
    "Choisissez ici un classificateur aisément multiclasse (par exemple un arbre de décision : [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) ou utilisez n'importe quel classificateur binaire en *OneVsRest*. Le code après va permettre de l'évaluer en validation croisée selon son exactitude.\n",
    "\n",
    "Nous allons étudier à quel point l'apport de nouveaux exemples aide l'apprentissage en favorisant la généralisation et quelle est la limite de la capacité d'un modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn. ... import ... \n",
    "\n",
    "# estimator = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes=np.linspace(.1, 1.0, 5)\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "        estimator, X_train, y_train, cv=5, n_jobs=-1, train_sizes=train_sizes, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Statistiques sur les différents plis pour affichage ensuite\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "valid_scores_std = np.std(valid_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "# Un écart-type sur les plis\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.3, color=\"r\")\n",
    "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std, valid_scores_mean + valid_scores_std, alpha=0.3, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, valid_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette figure montre que les 15K premiers exemples sont utiles. En ajouter d'autres n'aide pas vraiment l'apprentissage dû à la capacité limitée du modèle et au bruit aléatoire dans les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbe de validation\n",
    "\n",
    "Là où la courbe d'apprentissage mesure la performance en fonction du nombre d'exemples vus, la courbe de validation permet de mesurer la performance en fonction de la capacité du modèle et des hyperparamètres choisis. Dans l'exemple de code suivant (à compléter selon le modèle que vous avez choisi), il est possible de visualiser l'impact d'un seul hyperparamètre.\n",
    "\n",
    "Dans le cas de l'arbre de décision par exemple nous pourrions choisir l'hyperparamètre `max_depth` et le faire varier de manière exponentielle entre 1 et 256 : `[1,2,4,8,16,32,64,128]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_name = 'max_depth'\n",
    "param_range = [1,2,4,8,16,32,64,128,256]\n",
    "\n",
    "# Calcul de la courbe de validation au moyen de la validation croisée\n",
    "train_scores, valid_scores = validation_curve(estimator, X_train, y_train, param_name=hyper_name, param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "\n",
    "# Calcul de statistiques pour fins de visualisation\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "valid_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure()\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"hyperparameter\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.3, color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, valid_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, valid_scores_mean - valid_scores_std, valid_scores_mean + valid_scores_std, alpha=0.3, color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement d'un classificateur\n",
    "\n",
    "Nous avons vu comment choisir le bon nombre de plis selon la courbe d'apprentissage et comment tester les hyperparamètres un par un avec la courbe de validation. À vous maintenant d'essayer d'entraîner le meilleur modèle possible Scikit-Learn sur les données MNIST à l'aide de tous les outils dont vous disposez.\n",
    "\n",
    "Un exemple sommaire vous est donné ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-992b81333223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(min_samples_split=10, n_jobs=-1, verbose=1)\n",
    "score = cross_val_score(clf, X_train, y_train, cv=5, verbose=1, n_jobs=-1)\n",
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluer le modèle choisi sur l'ensemble de test\n",
    "\n",
    "Une fois que le classificateur est choisi avec le meilleur ensemble d'hyperparamètres, il est temps de réentraîner le modèle choisi au complet sur la totalité des données d'entraînement selon ces choix. Ce modèle sera testé sur l'ensemble de test. \n",
    "\n",
    "Si vous recommencez le processus après cela parce que vous n'êtes pas satisfait du résultat sur l'ensemble de test, vous commencez à *tricher* et à surapprendre (overfit) l'ensemble de test. La méthodologie devient bancale, et vous perdez toute garantie de fonctionnement en production (toujours sous l'hypothèse i.i.d  et que la distribution de génération des entrées ne change pas). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loadData('./MNIST/raw/train-images-idx3-ubyte.gz', 60000)\n",
    "y_train = loadLabels('./MNIST/raw/train-labels-idx1-ubyte.gz', 60000)\n",
    "X_test = loadData('./MNIST/raw/t10k-images-idx3-ubyte.gz', 10000)\n",
    "y_test = loadLabels('./MNIST/raw/t10k-labels-idx1-ubyte.gz', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N'hésitez pas à partager le résultat obtenu sur le forum en spécifiant le modèle, les hyperparamètres, et la graine de génération aléatoire choisie pour l'entraînement pour la réplicabilité de vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
